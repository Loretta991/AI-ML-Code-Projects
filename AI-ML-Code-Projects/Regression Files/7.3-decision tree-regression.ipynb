{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f8f9f-5d12-4196-9334-599bf0bb6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loretta Gray 7.3 Decision Tree Regression Commmeted Hw6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c698d5-7418-416c-aadb-c700d88e8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/11 02:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d7576e-581f-4eb5-add2-e9724988649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"file:///Users/ellegreyllc/Desktop/Advertising.csv\",header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f56451-936d-4a65-a806-86ffa2041735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a80e926-86a1-4a11-bc6b-bdcd35352339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/11 02:59:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5213871-cae2-4260-af6c-41116890d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to dense vector (features and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd89f6e8-ed7e-44f3-bd0e-0d71a77e177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "| 22.1|[230.1,37.8,69.2]|\n",
      "| 10.4| [44.5,39.3,45.1]|\n",
      "|  9.3| [17.2,45.9,69.3]|\n",
      "| 18.5|[151.5,41.3,58.5]|\n",
      "| 12.9|[180.8,10.8,58.4]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "transformed = df.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n",
    "transformed.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27c33d-59df-4fb1-9b34-554c58b4ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will find out that all of the machine learning algorithms in Spark are based on\n",
    "#the features and label. That is to say, you can play with all of the machine learning \n",
    "#algorithms in Spark when you get ready the features and label.\n",
    "\n",
    "#Deal with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02039369-555c-4737-8bf1-260226a6ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4\n",
    "# distinct values are treated as continuous.\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3cc13c-d2e5-4a60-bb46-4f8d607f8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-----------------+\n",
      "|label|         features|  indexedFeatures|\n",
      "+-----+-----------------+-----------------+\n",
      "| 22.1|[230.1,37.8,69.2]|[230.1,37.8,69.2]|\n",
      "| 10.4| [44.5,39.3,45.1]| [44.5,39.3,45.1]|\n",
      "|  9.3| [17.2,45.9,69.3]| [17.2,45.9,69.3]|\n",
      "| 18.5|[151.5,41.3,58.5]|[151.5,41.3,58.5]|\n",
      "| 12.9|[180.8,10.8,58.4]|[180.8,10.8,58.4]|\n",
      "+-----+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c9bd9-027e-4a2e-89cf-cc673b25f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6ac940-cd54-4501-b2de-9f7776d3027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a460836d-caa3-424e-8d2d-95d6a8ceb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----------------+\n",
      "|label|        features| indexedFeatures|\n",
      "+-----+----------------+----------------+\n",
      "|  1.6|  [0.7,39.6,8.7]|  [0.7,39.6,8.7]|\n",
      "|  4.8|   [8.6,2.1,1.0]|   [8.6,2.1,1.0]|\n",
      "|  5.3|  [5.4,29.9,9.4]|  [5.4,29.9,9.4]|\n",
      "|  5.5| [7.3,28.1,41.4]| [7.3,28.1,41.4]|\n",
      "|  5.6|[13.2,15.9,49.6]|[13.2,15.9,49.6]|\n",
      "+-----+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test datasets\n",
    "trainingData, testData = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "trainingData.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81f540-33c1-43be-9aab-d817aa8b18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afea3cde-645e-46c0-8842-38198297dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and decision tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ed673-a85a-4ba1-9c08-4c849249f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b6c2ef-504f-4d95-a67a-402a9eec9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3188bb32-c08a-41b1-9258-009fed05763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+-----------------+\n",
      "|        features|label|       prediction|\n",
      "+----------------+-----+-----------------+\n",
      "|  [4.1,11.6,5.7]|  3.2|              5.7|\n",
      "| [13.1,0.4,25.6]|  5.3|5.466666666666666|\n",
      "| [53.5,2.0,21.4]|  8.1|              8.4|\n",
      "| [66.1,5.8,24.2]|  8.6|             10.1|\n",
      "|[16.9,43.7,89.4]|  8.7|             8.96|\n",
      "+----------------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969db8c-9961-489e-83ed-a411260500ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cb6e692-72e5-4999-b421-765707306c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc7b88a-22b0-4b9f-b939-a2aa2570bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9454161819062926\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f97c6a-f1d2-486a-b5e5-79c135b1c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.6584, 1: 0.3329, 2: 0.0087})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eb1f8-913a-49c0-ba69-36fe3427d3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429f14a-3e76-42c4-95fb-fe7a5c579970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
