{"cells":[{"cell_type":"markdown","metadata":{"id":"aawc_hKCgelj"},"source":["<font size=5>\n","\n","Regression with boston_data.csv. Dataset downloaded from Kaggle, to predict Boston housing price\n","\n","\n","\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"377orErQgelk"},"source":["| Code   | Description   |\n","|:---|:---|\n","|**CRIM** | per capita crime rate by town |\n","|**ZN**  | proportion of residential land zoned for lots over 25,000 sq.ft. |\n","|**INDUS**  | proportion of non-retail business acres per town |\n","|**CHAS**  | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n","|**NOX**  | nitric oxides concentration (parts per 10 million) |\n","|**RM**  | average number of rooms per dwelling |\n","|**AGE**  | proportion of owner-occupied units built prior to 1940 |\n","|**DIS**  | weighted distances to five Boston employment centres |\n","|**RAD**  | index of accessibility to radial highways |\n","|**TAX**  | full-value property-tax rate per $10,000 |\n","|**PTRATIO**  | pupil-teacher ratio by town |\n","|**B**  | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town |\n","|**LSTAT**  | % lower status of the population |\n","|**MEDV**  | Median value of owner-occupied homes in \\$1000's |\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I5sEzbN-gell"},"source":["<font size=5>mdev is the label, all other columns are features. </font>"]},{"cell_type":"markdown","metadata":{"id":"7MJ6ErZ9gell"},"source":["<font size=5> Import PySpark libraries, create SparkContext and SQL context, then load the csv data file. </font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsnrosg0gell"},"outputs":[],"source":["import findspark\n","findspark.init()\n","from pyspark import SparkConf, SparkContext\n","from pyspark.sql import SQLContext\n","\n","sc= SparkContext()\n","sqlContext = SQLContext(sc)\n","boston_house_df = sqlContext.read.format('csv').options(header='true', inferschema='true')\\\n",".load('file:///opt/hadoop/jentekllc/Spark/datasets/BostonHousing.csv')"]},{"cell_type":"markdown","metadata":{"id":"0_TcNyEsgelm"},"source":["<font size=5> Show statistics of each column, including feature columns and label column (medv)  </font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kz9igC_5gelm","outputId":"13559ce0-04f2-4f01-b554-250943e62727"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>summary</th>\n","      <td>count</td>\n","      <td>mean</td>\n","      <td>stddev</td>\n","      <td>min</td>\n","      <td>max</td>\n","    </tr>\n","    <tr>\n","      <th>crim</th>\n","      <td>506</td>\n","      <td>3.6135235573122535</td>\n","      <td>8.601545105332491</td>\n","      <td>0.00632</td>\n","      <td>88.9762</td>\n","    </tr>\n","    <tr>\n","      <th>zn</th>\n","      <td>506</td>\n","      <td>11.363636363636363</td>\n","      <td>23.32245299451514</td>\n","      <td>0.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>indus</th>\n","      <td>506</td>\n","      <td>11.136778656126504</td>\n","      <td>6.860352940897589</td>\n","      <td>0.46</td>\n","      <td>27.74</td>\n","    </tr>\n","    <tr>\n","      <th>chas</th>\n","      <td>506</td>\n","      <td>0.0691699604743083</td>\n","      <td>0.2539940413404101</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>nox</th>\n","      <td>506</td>\n","      <td>0.5546950592885372</td>\n","      <td>0.11587767566755584</td>\n","      <td>0.385</td>\n","      <td>0.871</td>\n","    </tr>\n","    <tr>\n","      <th>rm</th>\n","      <td>506</td>\n","      <td>6.284634387351787</td>\n","      <td>0.7026171434153232</td>\n","      <td>3.561</td>\n","      <td>8.78</td>\n","    </tr>\n","    <tr>\n","      <th>age</th>\n","      <td>506</td>\n","      <td>68.57490118577078</td>\n","      <td>28.148861406903595</td>\n","      <td>2.9</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>dis</th>\n","      <td>506</td>\n","      <td>3.795042687747034</td>\n","      <td>2.10571012662761</td>\n","      <td>1.1296</td>\n","      <td>12.1265</td>\n","    </tr>\n","    <tr>\n","      <th>rad</th>\n","      <td>506</td>\n","      <td>9.549407114624506</td>\n","      <td>8.707259384239366</td>\n","      <td>1</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>tax</th>\n","      <td>506</td>\n","      <td>408.2371541501976</td>\n","      <td>168.53711605495903</td>\n","      <td>187</td>\n","      <td>711</td>\n","    </tr>\n","    <tr>\n","      <th>ptratio</th>\n","      <td>506</td>\n","      <td>18.455533596837967</td>\n","      <td>2.1649455237144455</td>\n","      <td>12.6</td>\n","      <td>22.0</td>\n","    </tr>\n","    <tr>\n","      <th>b</th>\n","      <td>506</td>\n","      <td>356.67403162055257</td>\n","      <td>91.29486438415782</td>\n","      <td>0.32</td>\n","      <td>396.9</td>\n","    </tr>\n","    <tr>\n","      <th>lstat</th>\n","      <td>506</td>\n","      <td>12.653063241106723</td>\n","      <td>7.141061511348571</td>\n","      <td>1.73</td>\n","      <td>37.97</td>\n","    </tr>\n","    <tr>\n","      <th>medv</th>\n","      <td>506</td>\n","      <td>22.532806324110698</td>\n","      <td>9.197104087379815</td>\n","      <td>5.0</td>\n","      <td>50.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0                   1                    2        3        4\n","summary  count                mean               stddev      min      max\n","crim       506  3.6135235573122535    8.601545105332491  0.00632  88.9762\n","zn         506  11.363636363636363    23.32245299451514      0.0    100.0\n","indus      506  11.136778656126504    6.860352940897589     0.46    27.74\n","chas       506  0.0691699604743083   0.2539940413404101        0        1\n","nox        506  0.5546950592885372  0.11587767566755584    0.385    0.871\n","rm         506   6.284634387351787   0.7026171434153232    3.561     8.78\n","age        506   68.57490118577078   28.148861406903595      2.9    100.0\n","dis        506   3.795042687747034     2.10571012662761   1.1296  12.1265\n","rad        506   9.549407114624506    8.707259384239366        1       24\n","tax        506   408.2371541501976   168.53711605495903      187      711\n","ptratio    506  18.455533596837967   2.1649455237144455     12.6     22.0\n","b          506  356.67403162055257    91.29486438415782     0.32    396.9\n","lstat      506  12.653063241106723    7.141061511348571     1.73    37.97\n","medv       506  22.532806324110698    9.197104087379815      5.0     50.0"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["boston_house_df.describe().toPandas().transpose()"]},{"cell_type":"markdown","metadata":{"id":"jeYqRazogeln"},"source":["<font size=5>\n","\n","We need to find out corelationship beween each feature column with label medv.  The corelationship is between 0 to |1|, the more close to -1, or 1, that means that feature column is more negatively or positively corelated to medv, the more close to 0, that means less or little corelationship between the feature column and label medv.\n","\n","   \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8P4YxrIbgeln"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tf6TWZtQgeln","outputId":"3a75dea8-01e1-4f25-eb32-272ebb2f8779"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correlation to medv for  crim -0.38830460858681154\n","Correlation to medv for  zn 0.3604453424505433\n","Correlation to medv for  indus -0.4837251600283728\n","Correlation to medv for  chas 0.1752601771902987\n","Correlation to medv for  nox -0.4273207723732821\n","Correlation to medv for  rm 0.6953599470715401\n","Correlation to medv for  age -0.3769545650045961\n","Correlation to medv for  dis 0.249928734085904\n","Correlation to medv for  rad -0.38162623063977735\n","Correlation to medv for  tax -0.46853593356776674\n","Correlation to medv for  ptratio -0.5077866855375622\n","Correlation to medv for  b 0.3334608196570661\n","Correlation to medv for  lstat -0.7376627261740145\n","Correlation to medv for  medv 1.0\n"]}],"source":["import six\n","for i in boston_house_df.columns:\n","    if not( isinstance(boston_house_df.select(i).take(1)[0][0], six.string_types)):\n","        print( \"Correlation to medv for \", i, boston_house_df.stat.corr('medv',i))"]},{"cell_type":"markdown","metadata":{"id":"ZbImlvSygeln"},"source":["<font size=5>\n","\n","Spark ML requires features of the dataset are vectorized before the dataset can be fit into ML model,\n","VectorAssembler is to convert a Spark Dataframe into Spark Vectorized Dataframe\n","\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuCCRtGkgeln","outputId":"92faba42-3dac-420c-8bbb-cf58f3cf2a87"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----+\n","|            features|medv|\n","+--------------------+----+\n","|[0.00632,18.0,2.3...|24.0|\n","|[0.02731,0.0,7.07...|21.6|\n","+--------------------+----+\n","only showing top 2 rows\n","\n"]}],"source":["from pyspark.ml.feature import VectorAssembler\n","vectorAssembler = VectorAssembler(inputCols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'features')\n","#vectorAssembler = VectorAssembler(inputCols = ['rm'], outputCol = 'features')\n","vector_house_df = vectorAssembler.transform(boston_house_df)\n","vector_house_df = vector_house_df.select(['features', 'medv'])\n","vector_house_df.show(2)"]},{"cell_type":"markdown","metadata":{"id":"FwtlZv3ggeln"},"source":["<font size=5>  \n","\n","Now randomly split Spark Vectorized DataFrame (dataset) into training data (70%) and testing data (30%)\n","    \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZJYvljLgelo","outputId":"c930bec4-c664-4637-dd1f-8be254ab768b"},"outputs":[{"name":"stdout","output_type":"stream","text":["138\n"]}],"source":["splits = vector_house_df.randomSplit([0.7, 0.3])\n","train_df = splits[0]\n","test_df = splits[1]\n","print(test_df.count())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCI_7Y_Hgelo","outputId":"105054d4-6f2f-4a05-e68f-b34cd551cc05"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----+\n","|            features|medv|\n","+--------------------+----+\n","|[0.00632,18.0,2.3...|24.0|\n","|[0.01096,55.0,2.2...|22.0|\n","+--------------------+----+\n","only showing top 2 rows\n","\n"]}],"source":["train_df.show(2)"]},{"cell_type":"markdown","metadata":{"id":"Q7sH8Leygelo"},"source":["<font size=5>\n","\n","Let's do Linear Regression first, fit the Linear Regression model with train_df\n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxVQPLd8gelo","outputId":"a0719658-78eb-4cf9-8cb8-3dff6450ec24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients: [-0.008705106328913166,0.006023590381011056,-0.057906071607189094,3.1847344475277866,-6.187200885207628,4.203725365598978,-8.763688222585704e-05,-0.6276537162738738,0.0,0.0,-0.799411786344425,0.008868403042993868,-0.4929121373907858]\n","Intercept: 20.292695035558626\n"]}],"source":["from pyspark.ml.regression import LinearRegression\n","lr = LinearRegression(featuresCol = 'features', labelCol='medv', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","lr_model = lr.fit(train_df)\n","print(\"Coefficients: \" + str(lr_model.coefficients))\n","print(\"Intercept: \" + str(lr_model.intercept))"]},{"cell_type":"markdown","metadata":{"id":"ifplDV65gelo"},"source":["<font size=5>\n","Linear Regression produced slope coefficients and intercept\n","\n","y=a1 X x1 + a2 X x2 +...+ an X xn + b\n","\n","a1,a2,...an are coefficients for the xn in their space\n","b is intercept\n","\n","x1, x2, ... xn are independent variables\n","\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBzdLGvUgelo","outputId":"f3cdc5d8-4a4f-4dd1-9ae1-92e4b848d87b"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 5.114079\n","r2: 0.691711\n"]}],"source":["trainingSummary = lr_model.summary\n","print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n","print(\"r2: %f\" % trainingSummary.r2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grfpFLL1gelo","outputId":"7a3bc819-14ff-4b16-b178-9e0aa7e7452a"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------------+\n","|summary|             medv|\n","+-------+-----------------+\n","|  count|              368|\n","|   mean|22.62690217391305|\n","| stddev|9.223146996202797|\n","|    min|              5.0|\n","|    max|             50.0|\n","+-------+-----------------+\n","\n"]}],"source":["train_df.describe().show()"]},{"cell_type":"markdown","metadata":{"id":"sSBeGNsKgelo"},"source":["<font size=5>\n","\n","Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n","\n","  \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHR-W9VZgelo","outputId":"c0038b3e-091e-481d-e0ea-0b2ad7ebe666"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+----+--------------------+\n","|        prediction|medv|            features|\n","+------------------+----+--------------------+\n","| 30.79578189766023|32.2|[0.00906,90.0,2.9...|\n","| 32.10188130417794|32.7|[0.01301,35.0,1.5...|\n","|30.113937760762752|35.4|[0.01311,90.0,1.2...|\n","|34.717089031603834|44.0|[0.01538,90.0,3.7...|\n","|25.633973841160756|21.6|[0.02731,0.0,7.07...|\n","+------------------+----+--------------------+\n","only showing top 5 rows\n","\n","R Squared (R2) on test data = 0.777433\n"]}],"source":["lr_predictions = lr_model.transform(test_df)\n","lr_predictions.select(\"prediction\",\"medv\",\"features\").show(5)\n","from pyspark.ml.evaluation import RegressionEvaluator\n","lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"r2\")\n","print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Twg4fadagelo","outputId":"74caac3c-f70c-459f-fc77-0d59fb17b57e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE) on test data = 4.30383\n"]}],"source":["test_result = lr_model.evaluate(test_df)\n","print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3hA83IUgelo","outputId":"de11fecf-fe2d-40d6-dc1f-718047440164"},"outputs":[{"name":"stdout","output_type":"stream","text":["numIterations: 11\n","objectiveHistory: [0.5, 0.433284889386758, 0.24842120216691616, 0.22711926490905993, 0.19675487395842117, 0.19348544217889674, 0.19292689313998745, 0.1921582874243395, 0.19124798715184915, 0.19079822667085858, 0.19061607284127202]\n","+-------------------+\n","|          residuals|\n","+-------------------+\n","|-6.8394305915109825|\n","|-5.8370462871607245|\n","+-------------------+\n","only showing top 2 rows\n","\n"]}],"source":["print(\"numIterations: %d\" % trainingSummary.totalIterations)\n","print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n","trainingSummary.residuals.show(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMTLBlbHgelp","outputId":"4aa0197d-622d-4e2c-b5d2-51928c5e9597"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+----+--------------------+\n","|        prediction|medv|            features|\n","+------------------+----+--------------------+\n","| 30.79578189766023|32.2|[0.00906,90.0,2.9...|\n","| 32.10188130417794|32.7|[0.01301,35.0,1.5...|\n","|30.113937760762752|35.4|[0.01311,90.0,1.2...|\n","|34.717089031603834|44.0|[0.01538,90.0,3.7...|\n","|25.633973841160756|21.6|[0.02731,0.0,7.07...|\n","+------------------+----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["predictions = lr_model.transform(test_df)\n","predictions.select(\"prediction\",\"medv\",\"features\").show(5)"]},{"cell_type":"markdown","metadata":{"id":"wMYXsTF1gelp"},"source":["<font size=5>\n","    \n","Now try Gradient Boost Tree Regressor with the same train_df and test_df\n","    \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCxDKZaHgelp"},"outputs":[],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.regression import GBTRegressor\n","from pyspark.ml.feature import VectorIndexer\n","from pyspark.ml.evaluation import RegressionEvaluator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FRlDelWgelp"},"outputs":[],"source":["gbt = GBTRegressor(featuresCol=\"features\",labelCol='medv', maxIter=10)\n","gbt_model = gbt.fit(train_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_n3yjxOngelp","outputId":"30737a5a-a4a4-4f48-e23d-43d5f8a2963b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+----+--------------------+\n","|        prediction|medv|            features|\n","+------------------+----+--------------------+\n","|31.901881375197288|32.2|[0.00906,90.0,2.9...|\n","| 34.59554945652568|32.7|[0.01301,35.0,1.5...|\n","|  34.7920240155147|35.4|[0.01311,90.0,1.2...|\n","| 45.71246197955683|44.0|[0.01538,90.0,3.7...|\n","| 20.23234916276675|21.6|[0.02731,0.0,7.07...|\n","+------------------+----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["gbt_predictions = gbt_model.transform(test_df)\n","gbt_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"]},{"cell_type":"markdown","metadata":{"id":"EFRxJEuDgelp"},"source":["<font size=5>\n","\n","Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n","\n","Looks like the metrics of Gradient Boost Tree are better that those of Linear Regressor\n","    \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvfi1qHrgelp","outputId":"ab6ad674-8b0c-44e0-c903-1cfadaa0b1cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["R Squared (R2) on test data = 0.824957\n"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"r2\")\n","print(\"R Squared (R2) on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4LWaI7egelp"},"outputs":[],"source":["gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"rmse\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2O8nxmUYgelp","outputId":"642a6fdf-ddb2-4388-9be7-7a2a52b11e9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE on test data = 3.81678\n"]}],"source":["print(\"RMSE on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"]},{"cell_type":"markdown","metadata":{"id":"D4mwkfpugelp"},"source":["<font size=5>\n","\n","Now try Random Forest Regressor with the same train_df and test_df\n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWjG5cpQgelp"},"outputs":[],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml.feature import VectorIndexer\n","from pyspark.ml.evaluation import RegressionEvaluator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wTPo5O9gelp"},"outputs":[],"source":["\n","rf = RandomForestRegressor(featuresCol=\"features\",labelCol='medv', maxDepth=3)\n","rf_model = rf.fit(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4drQhKxgelp","outputId":"ff8fad2f-1546-4c14-97e7-7ae06d3e3a39"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+----+--------------------+\n","|        prediction|medv|            features|\n","+------------------+----+--------------------+\n","|29.282180897063693|32.2|[0.00906,90.0,2.9...|\n","|31.653408126980445|32.7|[0.01301,35.0,1.5...|\n","| 32.40155126739403|35.4|[0.01311,90.0,1.2...|\n","|41.573830793016235|44.0|[0.01538,90.0,3.7...|\n","| 23.32195042099955|21.6|[0.02731,0.0,7.07...|\n","+------------------+----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["rf_predictions = rf_model.transform(test_df)\n","rf_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"]},{"cell_type":"markdown","metadata":{"id":"UhF9ibDggelp"},"source":["<font size=5>\n","    \n","Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n","\n","Looks like the metrics of Random Forest are better that those of Linear Regressor, but similar to those of Gradient Boost Tree\n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gs98dM9Vgelp","outputId":"0becd14d-f57c-4edb-bdf4-b5f681837ca5"},"outputs":[{"name":"stdout","output_type":"stream","text":["R Squared (R2) on test data = 0.797658\n"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"r2\")\n","print(\"R Squared (R2) on test data = %g\" % rf_evaluator.evaluate(rf_predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_sG-wqZgelu"},"outputs":[],"source":["rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"rmse\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_pXL0q3gelu","outputId":"9997a580-da40-4c25-9ed7-6cc918cd789a"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE on test data = 3.81678\n"]}],"source":["print(\"RMSE on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"]},{"cell_type":"markdown","metadata":{"id":"8T7SCq7Cgelu"},"source":["<font size=5>\n","\n","Finally, try Decision Tree regressor with the same train_df and test_df\n","    \n","    \n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xsvkp3ygelu"},"outputs":[],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml.feature import VectorIndexer\n","from pyspark.ml.evaluation import RegressionEvaluator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wpd1RpUHgelu"},"outputs":[],"source":["dt = DecisionTreeRegressor(featuresCol=\"features\",labelCol='medv', maxDepth=3)\n","dt_model = dt.fit(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uhz2mvVgelu","outputId":"858ebeff-8a34-4944-b0f1-bebb686d92b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+----+--------------------+\n","|        prediction|medv|            features|\n","+------------------+----+--------------------+\n","|         32.071875|32.2|[0.00906,90.0,2.9...|\n","|         32.071875|32.7|[0.01301,35.0,1.5...|\n","|         32.071875|35.4|[0.01311,90.0,1.2...|\n","|46.731578947368426|44.0|[0.01538,90.0,3.7...|\n","|23.002923976608184|21.6|[0.02731,0.0,7.07...|\n","+------------------+----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["dt_predictions = dt_model.transform(test_df)\n","dt_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"]},{"cell_type":"markdown","metadata":{"id":"rZTXrFqIgelu"},"source":["<font size=5>\n","    \n","Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n","\n","Looks like the metrics of Decision Tree Regressor are slightly better than that those of Linear Regressor, but not as good as Gradient Boost Tree and Random Forest\n","\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2We1fyY4gelu","outputId":"6194ba31-fecc-410d-d668-8e3206602590"},"outputs":[{"name":"stdout","output_type":"stream","text":["R Squared (R2) on test data = 0.751557\n"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"r2\")\n","print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(dt_predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZY4hlBBgelu"},"outputs":[],"source":["dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n","                 labelCol=\"medv\",metricName=\"rmse\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ITEIucwgelu","outputId":"10f496d4-61d0-4a60-f7be-49c22b6ba15f"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE on test data = 4.54714\n"]}],"source":["print(\"RMSE on test data = %g\" % dt_evaluator.evaluate(dt_predictions))"]},{"cell_type":"markdown","metadata":{"id":"IkySiI2Fgelu"},"source":["<font size=5>\n","\n","This concludes the testing of Spark ML regressors\n","\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J6EwDtXIgelu"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}