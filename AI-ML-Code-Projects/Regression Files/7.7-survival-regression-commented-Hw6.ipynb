{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da8c32-6a1a-4919-96b9-0217234eaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loretta Gray 7.7 Survival Regression Commented Hw6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b602a3a-4f76-48b7-95f2-3c5a3b6a996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize Spark and import necessary libraries:\n",
    "- findspark: Helps find and initialize PySpark.\n",
    "- SparkSession: The entry point for using Spark with DataFrames.\n",
    "- Vectors: Provides feature vector utilities for machine learning.\n",
    "- AFTSurvivalRegression: Implements Accelerated Failure Time (AFT) survival regression for time-to-event analysis.\n",
    "'''\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import AFTSurvivalRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b4501c-8a27-477c-86c3-5e964c232251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded as whas500.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Download the WHAS500 dataset from the web archive:\n",
    "- urllib.request: Module for opening and reading URLs.\n",
    "- urlretrieve: Downloads the file from the specified URL and saves it locally.\n",
    "- The file is saved as 'whas500.txt' in the current working directory.\n",
    "'''\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# Download the .txt file\n",
    "url = \"https://web.archive.org/web/20170517071528/http://www.umass.edu/statdata/statdata/data/whas500.txt\"\n",
    "urllib.request.urlretrieve(url, \"whas500.txt\")\n",
    "\n",
    "print(\"File downloaded as whas500.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bc2600-0e56-41e2-8da8-f40ef6daee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<title>Wayback Machine</title>\n",
      "<script src=\"//archive.org/includes/athena.js\" type=\"text/javascript\"></script>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read the first 5 lines of the downloaded file to check its contents:\n",
    "- open(\"whas500.txt\", \"r\"): Opens the 'whas500.txt' file in read mode.\n",
    "- file.readline().strip(): Reads each line and removes any leading/trailing whitespace.\n",
    "- The loop runs 5 times to print the first 5 lines of the file.\n",
    "'''\n",
    "\n",
    "with open(\"whas500.txt\", \"r\") as file:\n",
    "    for _ in range(5):\n",
    "        print(file.readline().strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d733056f-12f8-4b55-ab51-8c6c512c6a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/13 04:00:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Initialize a Spark session:\n",
    "- findspark.init(): Initializes the findspark module to locate Spark.\n",
    "- SparkSession.builder.appName(\"Survival Regression\"): Creates a Spark session named \"Survival Regression\" for your Spark application.\n",
    "- getOrCreate(): Either retrieves an existing Spark session or creates a new one if none exists.\n",
    "'''\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"Survival Regression\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38396f93-d5be-49ab-a180-4dced658f9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|     <!DOCTYPE|               html>|\n",
      "+--------------+--------------------+\n",
      "|        <html>|                NULL|\n",
      "|        <head>|                NULL|\n",
      "|<title>Wayback|     Machine</title>|\n",
      "|       <script|src=\"//archive.or...|\n",
      "|       <script|type=\"text/javasc...|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load the downloaded dataset into a Spark DataFrame:\n",
    "- spark.read.option(\"delimiter\", \" \"): Specifies that the delimiter used in the dataset is a space (\" \").\n",
    "- .csv(): Reads the file 'whas500.txt' from the specified path and loads it into a Spark DataFrame.\n",
    "- inferSchema=True: Automatically infers the data types for each column.\n",
    "- header=True: Uses the first row as the header, which contains column names.\n",
    "- df.show(5): Displays the first 5 rows of the loaded DataFrame to verify the content.\n",
    "'''\n",
    "\n",
    "df = spark.read.option(\"delimiter\", \" \").csv(\"/Users/ellegreyllc/Desktop/whas500.txt\", inferSchema=True, header=True)\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0d866d-1078-467d-a3e8-e6800718764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create or retrieve a Spark session:\n",
    "- SparkSession.builder: Initiates the process of creating a Spark session.\n",
    "- .appName(\"Survival Regression\"): Sets the name of the Spark session as \"Survival Regression\".\n",
    "- .getOrCreate(): Retrieves the existing session if one exists, or creates a new session if none is active.\n",
    "'''\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Survival Regression\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79a9e9e-5553-4551-86bd-abe8517c115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLogged Time To Failure Data\\nlabel = unit of time, say months, equipment fails censor = 1 means occured, \\nsay time (by the label) to failure, uncensored censor = 0 means censored, \\nfailure not occured, say time (by the label) to maintenance features contains\\nfeature columns, such as machine age and temperature, more example such as\\n\\nHaeat Attack Study: https://web.archive.org/web/20170517071528/http://www.umass.edu/statdata/statdata/data/whas500.txt\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Logged Time To Failure Data\n",
    "label = unit of time, say months, equipment fails censor = 1 means occured, \n",
    "say time (by the label) to failure, uncensored censor = 0 means censored, \n",
    "failure not occured, say time (by the label) to maintenance features contains\n",
    "feature columns, such as machine age and temperature, more example such as\n",
    "\n",
    "Haeat Attack Study: https://web.archive.org/web/20170517071528/http://www.umass.edu/statdata/statdata/data/whas500.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f72def-eac1-4ce9-8aaf-5e339df15533",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a training DataFrame for the survival regression model:\n",
    "- spark.createDataFrame(): Creates a DataFrame from the given data.\n",
    "- The data consists of tuples representing:\n",
    "  - label: The time to failure (or event).\n",
    "  - censor: 1.0 if the event (failure) occurred (uncensored), 0.0 if the event did not occur (censored).\n",
    "  - features: A dense vector of feature values (e.g., machine age, temperature).\n",
    "- .toDF(\"label\", \"censor\", \"features\"): Assigns column names to the DataFrame.\n",
    "'''\n",
    "\n",
    "training = spark.createDataFrame((\n",
    "    (1.218, 1.0, Vectors.dense(1.560, -0.605)), \n",
    "    (2.949, 0.0, Vectors.dense(0.346, 2.158)),\n",
    "    (3.627, 0.0, Vectors.dense(1.380, 0.231)), \n",
    "    (0.273, 1.0, Vectors.dense(0.520, 1.151)), \n",
    "    (4.199, 0.0, Vectors.dense(0.795, -0.226))\n",
    ")).toDF(\"label\", \"censor\", \"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b643a6-b530-47b9-bafc-4c8644a28942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------------+\n",
      "|label|censor|      features|\n",
      "+-----+------+--------------+\n",
      "|1.218|   1.0| [1.56,-0.605]|\n",
      "|2.949|   0.0| [0.346,2.158]|\n",
      "|3.627|   0.0|  [1.38,0.231]|\n",
      "|0.273|   1.0|  [0.52,1.151]|\n",
      "|4.199|   0.0|[0.795,-0.226]|\n",
      "+-----+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad5bc2c-d3e3-42c2-9cec-0110f689bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict 2 quantile time to failure at 30% chance and at 60% chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0702c89-1614-4418-898c-61bdb4874344",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set the quantile probabilities for prediction:\n",
    "- quantileProbabilities: A tuple that defines the probabilities at which we want to predict the time-to-event (failure or maintenance).\n",
    "  - 0.3: 30% probability for the first quantile.\n",
    "  - 0.9: 90% probability for the second quantile.\n",
    "'''\n",
    "\n",
    "quantileProbabilities = (0.3, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "434413b9-eb7a-4262-803d-9fbd8bf939f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with training data above with AFTSurvivalRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aca79fd4-1555-418e-a63f-7d8c3cf76e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/13 04:01:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the AFTSurvivalRegression model with specified parameters:\n",
    "- AFTSurvivalRegression(quantileProbabilities=quantileProbabilities, quantilesCol=\"quantiles\", censorCol=\"censor\", featuresCol=\"features\", labelCol=\"label\"):\n",
    "  - quantileProbabilities: The probabilities at which we want to predict the time-to-event (failure or maintenance).\n",
    "  - quantilesCol: The name of the column where the quantiles will be stored in the output.\n",
    "  - censorCol: The name of the column indicating whether the event was censored (1 for occurred, 0 for censored).\n",
    "  - featuresCol: The name of the column containing the feature vector (e.g., machine age, temperature).\n",
    "  - labelCol: The name of the column representing the label (time-to-event or failure).\n",
    "- .fit(training): Fits the model to the provided training data.\n",
    "'''\n",
    "\n",
    "aft = AFTSurvivalRegression(\n",
    "    quantileProbabilities=quantileProbabilities,\n",
    "    quantilesCol=\"quantiles\",\n",
    "    censorCol=\"censor\",\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "model = aft.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e49b02e0-663e-467c-9f5f-2bacef0dc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the coefficients, intercept and scale parameter for AFT survival regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eb23aa5-3223-4695-8464-dfe6be9946c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.4963068060199874,0.1984439397592834]\n",
      "Intercept: 2.6380905631560227\n",
      "Scale: 1.5472326865488455\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Print the model parameters:\n",
    "- model.coefficients: Displays the coefficients of the model, which represent the weights of each feature in the model.\n",
    "- model.intercept: Displays the intercept of the model, which is the bias term in the regression.\n",
    "- model.scale: Displays the scale parameter, which is used in the survival regression model to model the distribution of the event times.\n",
    "'''\n",
    "\n",
    "print(\"Coefficients: {}\".format(model.coefficients))\n",
    "print(\"Intercept: {}\".format(model.intercept))\n",
    "print(\"Scale: {}\".format(model.scale))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdd7892d-0f34-4b2b-92e2-c18575dfc9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntransform the data based on model\\nprediction = time unit to fail when censor = 1 uncensored prediction = time \\nunit to other event such as maintenance when censor = 0 (Censored) 1st \\nelement of quantiles = time unit at 30% chance 2nd element of\\nquantiles = time unit at 60% chance\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "transform the data based on model\n",
    "prediction = time unit to fail when censor = 1 uncensored prediction = time \n",
    "unit to other event such as maintenance when censor = 0 (Censored) 1st \n",
    "element of quantiles = time unit at 30% chance 2nd element of\n",
    "quantiles = time unit at 60% chance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ee20365-7992-45ef-9e38-573fc75382f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|label|censor|features      |prediction        |quantiles                              |\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|1.218|1.0   |[1.56,-0.605] |5.7189965530299   |[1.1603295951029091,20.78508418847804] |\n",
      "|2.949|0.0   |[0.346,2.158] |18.076458028588913|[3.6675401061563893,65.69696247756175] |\n",
      "|3.627|0.0   |[1.38,0.231]  |7.3818753657635   |[1.497711770733379,26.828640220976947] |\n",
      "|0.273|1.0   |[0.52,1.151]  |13.577581299077895|[2.754761130759772,49.3462739066917]   |\n",
      "|4.199|0.0   |[0.795,-0.226]|9.013093216625732 |[1.8286702406091546,32.757127857843415]|\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Transform the training data using the trained model:\n",
    "- .transform(training): Applies the trained model to the training data. It generates predictions and quantiles based on the model's calculations.\n",
    "- .show(truncate=False): Displays the resulting DataFrame with predictions and quantiles without truncating the values for better readability.\n",
    "'''\n",
    "\n",
    "model.transform(training).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52364728-9f07-4a8a-bf7b-a2ba77f2ef60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d62a0c-f620-406a-9da1-6d9356b63b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
