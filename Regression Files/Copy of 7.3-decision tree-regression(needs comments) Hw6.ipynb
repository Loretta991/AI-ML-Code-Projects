{"cells":[{"cell_type":"code","execution_count":null,"id":"653f8f9f-5d12-4196-9334-599bf0bb6422","metadata":{"id":"653f8f9f-5d12-4196-9334-599bf0bb6422"},"outputs":[],"source":["Loretta Gray 7.3 Decision Tree Regression Commmeted Hw6"]},{"cell_type":"code","execution_count":null,"id":"29c698d5-7418-416c-aadb-c700d88e8023","metadata":{"id":"29c698d5-7418-416c-aadb-c700d88e8023","outputId":"b5374b5b-c91c-449a-9eb1-5efb56bbeee7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","25/02/11 02:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n","25/02/11 02:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"]}],"source":["'''\n","This cell initializes Spark and creates a SparkSession.\n","1. Import findspark to configure PySpark for local environment.\n","2. Call findspark.init() to initialize Spark settings.\n","3. Import SparkSession from pyspark.sql.\n","4. Create a SparkSession using a builder pattern to configure the application name and any necessary settings.\n","'''\n","\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark regression example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()\n"]},{"cell_type":"code","execution_count":null,"id":"d6d7576e-581f-4eb5-add2-e9724988649e","metadata":{"id":"d6d7576e-581f-4eb5-add2-e9724988649e","outputId":"618b8cf9-6c35-4d32-b8cb-e04d886fe304"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["'''\n","This cell reads a CSV file into a DataFrame using Spark.\n","1. Use spark.read.format('csv') to specify the file format as CSV.\n","2. Set options for the CSV file:\n","   - header='true' to treat the first row as the header.\n","   - inferschema='true' to automatically infer column data types.\n","3. Load the CSV file from the specified path and store it in a DataFrame 'df'.\n","'''\n","\n","df = spark.read.format('csv').\\\n","                       options(header='true', \\\n","                       inferschema='true').\\\n","            load(\"file:///Users/ellegreyllc/Desktop/Advertising.csv\",header=True)\n"]},{"cell_type":"code","execution_count":null,"id":"42f56451-936d-4a65-a806-86ffa2041735","metadata":{"id":"42f56451-936d-4a65-a806-86ffa2041735","outputId":"0dc7e27c-0eec-4571-f19d-bdf30332f9e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----+---------+-----+\n","|   TV|Radio|Newspaper|Sales|\n","+-----+-----+---------+-----+\n","|230.1| 37.8|     69.2| 22.1|\n","| 44.5| 39.3|     45.1| 10.4|\n","| 17.2| 45.9|     69.3|  9.3|\n","|151.5| 41.3|     58.5| 18.5|\n","|180.8| 10.8|     58.4| 12.9|\n","+-----+-----+---------+-----+\n","only showing top 5 rows\n","\n","root\n"," |-- TV: double (nullable = true)\n"," |-- Radio: double (nullable = true)\n"," |-- Newspaper: double (nullable = true)\n"," |-- Sales: double (nullable = true)\n","\n"]}],"source":["'''\n","This cell displays the first 5 rows of the DataFrame and prints its schema.\n","1. df.show(5, True) shows the first 5 rows of the DataFrame, including column names and data types.\n","2. df.printSchema() prints the schema of the DataFrame, showing column names and inferred data types.\n","'''\n","\n","df.show(5,True)\n","df.printSchema()\n"]},{"cell_type":"code","execution_count":null,"id":"8a80e926-86a1-4a11-bc6b-bdcd35352339","metadata":{"id":"8a80e926-86a1-4a11-bc6b-bdcd35352339","outputId":"08860f7e-871e-4dc3-c37f-cbe8a50d7559"},"outputs":[{"name":"stderr","output_type":"stream","text":["25/02/11 02:59:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"]},{"name":"stdout","output_type":"stream","text":["+-------+-----------------+------------------+------------------+------------------+\n","|summary|               TV|             Radio|         Newspaper|             Sales|\n","+-------+-----------------+------------------+------------------+------------------+\n","|  count|              200|               200|               200|               200|\n","|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n","| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n","|    min|              0.7|               0.0|               0.3|               1.6|\n","|    max|            296.4|              49.6|             114.0|              27.0|\n","+-------+-----------------+------------------+------------------+------------------+\n","\n"]}],"source":["'''\n","This cell provides summary statistics for the DataFrame.\n","1. df.describe() generates summary statistics for all numeric columns (e.g., count, mean, standard deviation, min, max).\n","2. .show() displays the summary statistics in the output.\n","'''\n","\n","df.describe().show()\n"]},{"cell_type":"code","execution_count":null,"id":"a5213871-cae2-4260-af6c-41116890d6b9","metadata":{"id":"a5213871-cae2-4260-af6c-41116890d6b9"},"outputs":[],"source":["#Convert the data to dense vector (features and label)"]},{"cell_type":"code","execution_count":null,"id":"bd89f6e8-ed7e-44f3-bd0e-0d71a77e177e","metadata":{"id":"bd89f6e8-ed7e-44f3-bd0e-0d71a77e177e","outputId":"bca901ff-7e64-407a-be19-373c7ac161cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----+-----------------+\n","|label|         features|\n","+-----+-----------------+\n","| 22.1|[230.1,37.8,69.2]|\n","| 10.4| [44.5,39.3,45.1]|\n","|  9.3| [17.2,45.9,69.3]|\n","| 18.5|[151.5,41.3,58.5]|\n","| 12.9|[180.8,10.8,58.4]|\n","+-----+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["'''\n","This cell transforms the DataFrame into a format suitable for machine learning.\n","1. Import Row from pyspark.sql and Vectors from pyspark.ml.linalg.\n","2. Convert the DataFrame to an RDD and use map() to transform each row:\n","   - r[-1] extracts the last column as the label.\n","   - Vectors.dense(r[:-1]) converts the remaining columns into a dense feature vector.\n","3. Convert the transformed RDD back to a DataFrame with columns 'label' and 'features'.\n","4. Display the first 5 rows of the transformed DataFrame.\n","'''\n","\n","from pyspark.sql import Row\n","from pyspark.ml.linalg import Vectors\n","\n","transformed = df.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n","transformed.show(5)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"de27c33d-59df-4fb1-9b34-554c58b4ff89","metadata":{"id":"de27c33d-59df-4fb1-9b34-554c58b4ff89"},"outputs":[],"source":["#You will find out that all of the machine learning algorithms in Spark are based on\n","#the features and label. That is to say, you can play with all of the machine learning\n","#algorithms in Spark when you get ready the features and label.\n","\n","#Deal with categorical variables"]},{"cell_type":"code","execution_count":null,"id":"02039369-555c-4737-8bf1-260226a6ab1a","metadata":{"id":"02039369-555c-4737-8bf1-260226a6ab1a"},"outputs":[],"source":["'''\n","This cell sets up a feature indexer for machine learning and applies it to the DataFrame.\n","1. Import necessary modules for pipeline, regression, and evaluation.\n","2. VectorIndexer automatically identifies categorical features and indexes them:\n","   - inputCol specifies the input column with features.\n","   - outputCol specifies the output column where the indexed features will be stored.\n","   - maxCategories=4 ensures that features with more than 4 distinct values are treated as continuous.\n","3. Fit the feature indexer to the transformed data and transform it to create indexed features.\n","'''\n","\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import VectorIndexer\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Automatically identify categorical features, and index them.\n","# We specify maxCategories so features with > 4\n","# distinct values are treated as continuous.\n","\n","featureIndexer = VectorIndexer(inputCol=\"features\", \\\n","                               outputCol=\"indexedFeatures\",\\\n","                               maxCategories=4).fit(transformed)\n","\n","data = featureIndexer.transform(transformed)\n"]},{"cell_type":"code","execution_count":null,"id":"9a3cc13c-d2e5-4a60-bb46-4f8d607f8bd6","metadata":{"id":"9a3cc13c-d2e5-4a60-bb46-4f8d607f8bd6","outputId":"639e571e-9f0e-4c16-a564-15a86ec51f98"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------------+-----------------+\n","|label|         features|  indexedFeatures|\n","+-----+-----------------+-----------------+\n","| 22.1|[230.1,37.8,69.2]|[230.1,37.8,69.2]|\n","| 10.4| [44.5,39.3,45.1]| [44.5,39.3,45.1]|\n","|  9.3| [17.2,45.9,69.3]| [17.2,45.9,69.3]|\n","| 18.5|[151.5,41.3,58.5]|[151.5,41.3,58.5]|\n","| 12.9|[180.8,10.8,58.4]|[180.8,10.8,58.4]|\n","+-----+-----------------+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["'''\n","This cell displays the first 5 rows of the transformed DataFrame with indexed features.\n","1. data.show(5) shows the first 5 rows of the DataFrame with the indexed features, allowing you to check how the transformation has been applied.\n","'''\n","\n","data.show(5)\n"]},{"cell_type":"code","execution_count":null,"id":"f00c9bd9-027e-4a2e-89cf-cc673b25f1f9","metadata":{"id":"f00c9bd9-027e-4a2e-89cf-cc673b25f1f9"},"outputs":[],"source":["#Fit Decision Tree Regression Model"]},{"cell_type":"code","execution_count":null,"id":"1a6ac940-cd54-4501-b2de-9f7776d3027f","metadata":{"id":"1a6ac940-cd54-4501-b2de-9f7776d3027f"},"outputs":[],"source":["'''\n","This cell sets up a DecisionTreeRegressor for training the model.\n","1. Import DecisionTreeRegressor from pyspark.ml.regression.\n","2. Instantiate a DecisionTreeRegressor model, specifying the input column for features (indexedFeatures) that will be used for training.\n","'''\n","\n","from pyspark.ml.regression import DecisionTreeRegressor\n","\n","# Train a DecisionTree model.\n","dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n"]},{"cell_type":"code","execution_count":null,"id":"a460836d-caa3-424e-8d2d-95d6a8ceb92e","metadata":{"id":"a460836d-caa3-424e-8d2d-95d6a8ceb92e","outputId":"c37f4a57-2d13-42c2-b9bc-bd711da11545"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+----------------+----------------+\n","|label|        features| indexedFeatures|\n","+-----+----------------+----------------+\n","|  1.6|  [0.7,39.6,8.7]|  [0.7,39.6,8.7]|\n","|  4.8|   [8.6,2.1,1.0]|   [8.6,2.1,1.0]|\n","|  5.3|  [5.4,29.9,9.4]|  [5.4,29.9,9.4]|\n","|  5.5| [7.3,28.1,41.4]| [7.3,28.1,41.4]|\n","|  5.6|[13.2,15.9,49.6]|[13.2,15.9,49.6]|\n","+-----+----------------+----------------+\n","only showing top 5 rows\n","\n"]}],"source":["'''\n","This cell splits the data into training and test datasets.\n","1. Use data.randomSplit() to randomly split the data into training (80%) and test (20%) datasets.\n","2. The seed ensures the split is reproducible.\n","3. Show the first 5 rows of the training dataset to verify the split.\n","'''\n","\n","# split data into training and test datasets\n","trainingData, testData = data.randomSplit([0.8, 0.2], seed=1234)\n","trainingData.show(5)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5a81f540-33c1-43be-9aab-d817aa8b18a3","metadata":{"id":"5a81f540-33c1-43be-9aab-d817aa8b18a3"},"outputs":[],"source":["#Pipeline Architecture"]},{"cell_type":"code","execution_count":null,"id":"afea3cde-645e-46c0-8842-38198297dfef","metadata":{"id":"afea3cde-645e-46c0-8842-38198297dfef"},"outputs":[],"source":["'''\n","This cell chains the feature indexer and decision tree into a Pipeline and trains the model.\n","1. Create a Pipeline by specifying the stages:\n","   - featureIndexer: the feature indexing step.\n","   - dt: the decision tree regression model.\n","2. Fit the pipeline to the training data to create the model.\n","'''\n","\n","# Chain indexer and decision tree in a Pipeline\n","pipeline = Pipeline(stages=[featureIndexer, dt])\n","\n","model = pipeline.fit(trainingData)\n"]},{"cell_type":"code","execution_count":null,"id":"2c5ed673-a85a-4ba1-9c08-4c849249f65e","metadata":{"id":"2c5ed673-a85a-4ba1-9c08-4c849249f65e"},"outputs":[],"source":["#Make predictions"]},{"cell_type":"code","execution_count":null,"id":"d9b6c2ef-504f-4d95-a67a-402a9eec9e09","metadata":{"id":"d9b6c2ef-504f-4d95-a67a-402a9eec9e09"},"outputs":[],"source":["'''\n","This cell makes predictions using the trained model on the test data.\n","1. Use model.transform(testData) to apply the trained pipeline model to the test dataset.\n","2. This will generate predictions, which include the predicted label and features.\n","'''\n","\n","# Make predictions.\n","predictions = model.transform(testData)\n"]},{"cell_type":"code","execution_count":null,"id":"3188bb32-c08a-41b1-9258-009fed05763d","metadata":{"id":"3188bb32-c08a-41b1-9258-009fed05763d","outputId":"c8f78d08-f168-48cc-c396-7187630d8e55"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------+-----+-----------------+\n","|        features|label|       prediction|\n","+----------------+-----+-----------------+\n","|  [4.1,11.6,5.7]|  3.2|              5.7|\n","| [13.1,0.4,25.6]|  5.3|5.466666666666666|\n","| [53.5,2.0,21.4]|  8.1|              8.4|\n","| [66.1,5.8,24.2]|  8.6|             10.1|\n","|[16.9,43.7,89.4]|  8.7|             8.96|\n","+----------------+-----+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["'''\n","This cell selects and displays specific columns from the predictions.\n","1. Use predictions.select() to select the \"features\", \"label\", and \"prediction\" columns.\n","2. .show(5) displays the first 5 rows of the selected columns to review the predictions.\n","'''\n","\n","# Select example rows to display.\n","predictions.select(\"features\",\"label\",\"prediction\").show(5)\n"]},{"cell_type":"code","execution_count":null,"id":"d969db8c-9961-489e-83ed-a411260500ea","metadata":{"id":"d969db8c-9961-489e-83ed-a411260500ea"},"outputs":[],"source":["#Evaluation"]},{"cell_type":"code","execution_count":null,"id":"9cb6e692-72e5-4999-b421-765707306c31","metadata":{"id":"9cb6e692-72e5-4999-b421-765707306c31"},"outputs":[],"source":["'''\n","This cell evaluates the model's performance using the Root Mean Squared Error (RMSE).\n","1. Import RegressionEvaluator from pyspark.ml.evaluation.\n","2. Instantiate a RegressionEvaluator to compute the RMSE:\n","   - labelCol specifies the column containing the true labels.\n","   - predictionCol specifies the column containing the predicted labels.\n","   - metricName=\"rmse\" tells the evaluator to compute RMSE.\n","3. Use evaluator.evaluate(predictions) to calculate the RMSE based on the predictions.\n","'''\n","\n","# from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Select (prediction, true label) and compute test error\n","evaluator = RegressionEvaluator(labelCol=\"label\",\n","                                predictionCol=\"prediction\",\n","                                metricName=\"rmse\")\n","\n","rmse = evaluator.evaluate(predictions)\n"]},{"cell_type":"code","execution_count":null,"id":"7bc7b88a-22b0-4b9f-b939-a2aa2570bb92","metadata":{"id":"7bc7b88a-22b0-4b9f-b939-a2aa2570bb92","outputId":"5f03d142-f603-4476-9e2e-ce8dcca18569"},"outputs":[{"name":"stdout","output_type":"stream","text":["r2_score: 0.9454161819062926\n"]}],"source":["'''\n","This cell calculates the R-squared (R²) score to evaluate the model's performance.\n","1. Convert the \"label\" and \"prediction\" columns of the predictions DataFrame into pandas DataFrames (y_true and y_pred).\n","2. Import sklearn.metrics to use the r2_score function.\n","3. Use sklearn.metrics.r2_score() to compute the R² score based on true labels (y_true) and predicted values (y_pred).\n","4. Print the R² score.\n","'''\n","\n","y_true = predictions.select(\"label\").toPandas()\n","y_pred = predictions.select(\"prediction\").toPandas()\n","\n","import sklearn.metrics\n","r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n","print('r2_score: {0}'.format(r2_score))\n"]},{"cell_type":"code","execution_count":null,"id":"d6f97c6a-f1d2-486a-b5e5-79c135b1c352","metadata":{"id":"d6f97c6a-f1d2-486a-b5e5-79c135b1c352","outputId":"072b7a66-22ab-419b-970a-cd33922d45a6"},"outputs":[{"data":{"text/plain":["SparseVector(3, {0: 0.6584, 1: 0.3329, 2: 0.0087})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","This cell extracts the feature importances from the trained model.\n","1. Access the last stage of the pipeline (the decision tree model) using model.stages[-1].\n","2. Use the .featureImportances attribute to retrieve the importance of each feature used by the model.\n","'''\n","\n","model.stages[-1].featureImportances\n"]},{"cell_type":"code","execution_count":null,"id":"b64eb1f8-913a-49c0-ba69-36fe3427d3bd","metadata":{"id":"b64eb1f8-913a-49c0-ba69-36fe3427d3bd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a429f14a-3e76-42c4-95fb-fe7a5c579970","metadata":{"id":"a429f14a-3e76-42c4-95fb-fe7a5c579970"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[{"file_id":"1XB2g8X2m0xZFQFiUbtctMot7eaui1KI2","timestamp":1739449432178}]}},"nbformat":4,"nbformat_minor":5}