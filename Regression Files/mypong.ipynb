{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8ediXYbqzOWJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy\u003e=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Requirement already satisfied: gym-notices\u003e=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/jaxlib/xla_client.py:225: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n","  float8_e4m3b11fnuz = ml_dtypes.float8_e4m3b11\n"]},{"ename":"NameNotFound","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-8b58e8c775b9\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 48\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Initialize the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 48\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pong-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;31m#env = gym.make('Breakout-v0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 607\u001b[0;31m             \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No registered env with id: {id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 234\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 212\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;34mf\"Environment {name} doesn't exist{namespace_msg}. {suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n","\u001b[0;31mNameNotFound\u001b[0m: Environment Pong doesn't exist. "]}],"source":["!pip install --upgrade pip\n","!pip install gym\n","import gym\n","import numpy as np\n","from tensorflow import keras\n","\n","# Define the Deep Q-Network (DQN) class\n","class DQNAgent:\n","    def __init__(self, state_shape, action_space):\n","        self.state_shape = state_shape\n","        self.action_space = action_space\n","        self.gamma = 0.99  # Discount factor\n","        self.epsilon = 1.0  # Exploration rate\n","        self.epsilon_decay = 0.995  # Rate at which exploration rate decays\n","        self.epsilon_min = 0.01  # Minimum exploration rate\n","        self.learning_rate = 0.001  # Learning rate\n","\n","        self.model = self.build_model()\n","\n","    def build_model(self):\n","        model = keras.Sequential()\n","        model.add(keras.layers.Conv2D(32, kernel_size=(8, 8), strides=(4, 4), activation='relu', input_shape=self.state_shape))\n","        model.add(keras.layers.Conv2D(64, kernel_size=(4, 4), strides=(2, 2), activation='relu'))\n","        model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","        model.add(keras.layers.Flatten())\n","        model.add(keras.layers.Dense(512, activation='relu'))\n","        model.add(keras.layers.Dense(self.action_space, activation='linear'))\n","        model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=self.learning_rate))\n","        return model\n","\n","    def act(self, state):\n","        if np.random.rand() \u003c= self.epsilon:\n","            return np.random.randint(self.action_space)\n","        q_values = self.model.predict(state)\n","        return np.argmax(q_values[0])\n","\n","    def train(self, state, action, reward, next_state, done):\n","        target = reward\n","        if not done:\n","            target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n","        target_f = self.model.predict(state)\n","        target_f[0][action] = target\n","        self.model.fit(state, target_f, epochs=1, verbose=0)\n","        if self.epsilon \u003e self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","# Initialize the environment\n","env = gym.make('Pong-v0')\n","#env = gym.make('Breakout-v0')\n","\n","# Extract state shape and action space information\n","state_shape = env.observation_space.shape\n","action_space = env.action_space.n\n","\n","# Initialize the DQN agent\n","agent = DQNAgent(state_shape, action_space)\n","\n","# Training parameters\n","num_games = 5\n","max_steps = 10000\n","\n","# Training loop\n","for game in range(num_games):\n","    state = env.reset()\n","    state = np.reshape(state, [1] + list(state_shape))\n","\n","    for step in range(max_steps):\n","        env.render()\n","\n","        # Agent selects an action\n","        action = agent.act(state)\n","\n","        # Perform the action and observe the next state, reward, and done flag\n","        next_state, reward, done, _ = env.step(action)\n","        next_state = np.reshape(next_state, [1] + list(state_shape))\n","\n","        # Reward shaping\n","        if reward == 1:  # If player wins a point\n","            reward = 10\n","        elif reward == -1:  # If opponent wins a point\n","            reward = -10\n","        else:\n","            reward\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPcYwe2M9KdwvzyHXnTHrzz","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}